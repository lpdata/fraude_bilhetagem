# üöç Detec√ß√£o de Fraudes em Sistemas de Bilhetagem Eletr√¥nica


## üìå Contexto e Objetivo

Sistemas de transporte utilizam amplamente a bilhetagem eletr√¥nica como meio de controle de acesso e arrecada√ß√£o tarif√°ria. Nesse contexto, fraudes em transa√ß√µes representam um problema recorrente, com impactos financeiros e operacionais relevantes para o sistema.

Foi disponibilizado um conjunto de dados contendo **30.000 registros hist√≥ricos de transa√ß√µes de bilhetagem**, com atributos relacionados ao cart√£o, ao usu√°rio e √†s circunst√¢ncias da transa√ß√£o. O objetivo central do projeto √© **explorar esse conjunto de dados e desenvolver modelos preditivos capazes de identificar ocorr√™ncias de fraude**, seguindo boas pr√°ticas de Ci√™ncia de Dados e Aprendizado de M√°quina.

### Desafios do Problema

Ainda que os desafios espec√≠ficos sejam analisados ao longo do projeto, o problema apresenta, de forma geral, caracter√≠sticas que tornam a tarefa de detec√ß√£o de fraude n√£o trivial, tais como:

- Diferen√ßa de frequ√™ncia entre transa√ß√µes leg√≠timas e fraudulentas.
- Impacto operacional associado a decis√µes automatizadas incorretas.
- Necessidade de compreens√£o e explica√ß√£o das decis√µes do modelo.
- Depend√™ncia exclusiva de dados hist√≥ricos internos ao sistema.

Diante disso, o projeto foi estruturado em etapas bem definidas: an√°lise explorat√≥ria, tratamento de dados, engenharia de features e modelagem, com o objetivo de avaliar de forma transparente e criteriosa as possibilidades e limita√ß√µes dos modelos constru√≠dos.


## üìÇ Estrutura do Reposit√≥rio

- **data/**
  - **raw/**
    - `dados.csv`
    - `Dicion√°rio de Dados.pdf`
  - **processed/**
    - `dados_tratados.csv`
    - `schema_dados_tratados.json`
    - `metadados_colunas.csv`
    - `metadados_dataset.json`

- **notebooks/**
  - `01_exploracao_dados.ipynb`
  - `02_tratamento_features.ipynb`
  - `03_modelagem.ipynb`

- **outputs/**
  - `matrizes_confusao_modelos.png`

- **src/**
  - `features.py`
  - `preprocessing.py`
  - `models.py`
  - `metrics.py`

- `README.md`
- `requirements.txt`


## üìò Dicion√°rio de Dados (Features Originais)

O conjunto de dados original √© composto por 30.000 registros de transa√ß√µes de bilhetagem eletr√¥nica e diversas vari√°veis operacionais e cadastrais. Abaixo s√£o apresentadas algumas das colunas mais relevantes:

| Coluna | Descri√ß√£o | Tipo |
|------|-----------|------|
| id_transacao | Identificador √∫nico da transa√ß√£o. | Int |
| id_cartao | Identificador √∫nico do cart√£o (usu√°rio). | Int |
| ts_transacao | Timestamp (data e hora) do uso na catraca. | Datetime |
| valor_transacao | Valor debitado no momento do giro da catraca. | Float |
| target_fraude | Vari√°vel Alvo: 1 para Fraude Confirmada, 0 para Normal. | Binary |

O dicion√°rio completo, contendo todas as vari√°veis originais do dataset, encontra-se no arquivo **Dicion√°rio de Dados.pdf**, dispon√≠vel na pasta `data/raw/`.

## üîç An√°lise Explorat√≥ria dos Dados

A an√°lise explorat√≥ria foi conduzida ao longo das etapas iniciais do projeto, com o objetivo de compreender a estrutura do dataset, a natureza do problema de fraude e os principais padr√µes associados ao uso dos cart√µes. Essa etapa orientou tanto a engenharia de features quanto as decis√µes posteriores de modelagem.

### Estrutura e Qualidade dos Dados

O conjunto de dados apresenta volume adequado e estrutura consistente para fins de modelagem preditiva. As vari√°veis temporais, categ√≥ricas e num√©ricas encontram-se bem definidas, permitindo an√°lises sob diferentes perspectivas comportamentais e contextuais. N√£o foram identificados problemas cr√≠ticos de integridade que inviabilizassem o uso dos dados, embora algumas vari√°veis demandassem tratamento e padroniza√ß√£o em etapas posteriores.

### Vari√°vel Alvo e Desbalanceamento

A vari√°vel alvo `target_fraude` apresenta desbalanceamento, com predomin√¢ncia de transa√ß√µes normais em rela√ß√£o √†s fraudulentas. Esse cen√°rio refor√ßa a necessidade de cuidado na escolha das m√©tricas de avalia√ß√£o e na interpreta√ß√£o dos resultados, especialmente considerando o impacto operacional de falsos positivos sinalizado pela √°rea de neg√≥cio.

### Padr√µes Temporais e Contextuais

As an√°lises temporais, como hora do dia, dia da semana e tempo de vida do cart√£o, indicaram varia√ß√µes discretas na taxa de fraude, sem padr√µes determin√≠sticos claros quando observadas de forma isolada. Vari√°veis de contexto operacional, como integra√ß√£o tarif√°ria e limites de uso, tamb√©m apresentaram baixo poder discriminante individual, sugerindo atua√ß√£o apenas como sinais auxiliares quando combinadas a outros atributos.

### Perfil do Usu√°rio e Caracter√≠sticas da Transa√ß√£o

Vari√°veis demogr√°ficas e cadastrais n√£o demonstraram diferen√ßas relevantes entre transa√ß√µes normais e fraudulentas. Da mesma forma, o valor da transa√ß√£o, analisado isoladamente, apresentou forte sobreposi√ß√£o entre os grupos, indicando que n√£o constitui um indicador direto de fraude neste contexto. Por outro lado, o tipo de cart√£o apresentou diferen√ßas mais expressivas na taxa de fraude, sugerindo influ√™ncia do perfil do benef√≠cio no risco associado.

### Comportamento de Uso dos Cart√µes

A an√°lise comportamental evidenciou que m√©tricas simples de frequ√™ncia ou intervalo entre transa√ß√µes n√£o s√£o suficientes, isoladamente, para diferenciar cart√µes com e sem fraude. Em contrapartida, atributos relacionados √† diversidade e dispers√£o de uso mostraram associa√ß√£o mais consistente com a ocorr√™ncia de fraude, como a utiliza√ß√£o de m√∫ltiplas linhas e dispositivos distintos, indicando padr√µes operacionais menos previs√≠veis.

### Direcionamento para as Etapas Seguintes

De forma geral, os resultados explorat√≥rios indicam que a fraude n√£o se manifesta por meio de regras simples ou limiares fixos, mas sim por combina√ß√µes de padr√µes comportamentais. Esses achados fundamentaram a etapa de engenharia de features e refor√ßaram a necessidade de modelos interpret√°veis, avaliados com m√©tricas alinhadas ao impacto operacional do problema.


## üß† Engenharia de Features

A etapa de engenharia de features teve como objetivo transformar a base transacional bruta em um dataset analiticamente consistente, rastre√°vel e adequado √† modelagem preditiva. O foco n√£o foi apenas aumentar o n√∫mero de vari√°veis, mas **representar padr√µes comportamentais e temporais relevantes ao problema de fraude**, mantendo clareza e controle sobre cada transforma√ß√£o aplicada.

### Vis√£o Geral do Dataset Final

| Elemento | Descri√ß√£o |
|-------|----------|
| Registros | 30.000 transa√ß√µes |
| Total de colunas | 42 |
| Colunas de rastreio | Garantem auditabilidade e depura√ß√£o |
| Vari√°vel alvo | Isolada e protegida contra vazamentos |
| Features derivadas | 38 vari√°veis constru√≠das de forma incremental |

A rela√ß√£o completa das features criadas, com tipos e descri√ß√µes detalhadas, est√° documentada nos arquivos de metadados dispon√≠veis em `data/processed/`.

### Eixos Principais da Engenharia de Features

Em vez de depender de atributos isolados, a engenharia de features foi organizada em **quatro eixos conceituais**, descritos a seguir.

#### ‚è±Ô∏è Enriquecimento temporal e sequencial

Foram criadas vari√°veis voltadas √† din√¢mica de uso do cart√£o ao longo do tempo, permitindo capturar padr√µes que n√£o emergem em an√°lises pontuais.

Principais ideias exploradas:
- Intervalo desde a √∫ltima transa√ß√£o
- Frequ√™ncia de uso em janelas m√≥veis
- Identifica√ß√£o de uso em intervalos curtos
- Flags de uso intenso em per√≠odos reduzidos

Essas features permitem identificar comportamentos acelerados ou fora do padr√£o esperado.

#### üß≠ Comportamento di√°rio e consist√™ncia operacional

Esse eixo buscou representar **estabilidade versus ruptura de padr√£o** no uso cotidiano do cart√£o.

Foram consideradas, por exemplo:
- Quantidade de linhas distintas utilizadas no dia
- Quantidade de dispositivos distintos por dia
- Repeti√ß√£o de linha ou dispositivo em transa√ß√µes consecutivas

Esses sinais ajudam a diferenciar comportamentos recorrentes leg√≠timos de sequ√™ncias operacionais at√≠picas.

#### üßæ Consolida√ß√£o do hist√≥rico do cart√£o

Agrega√ß√µes por cart√£o permitiram construir uma vis√£o de longo prazo do comportamento individual, funcionando como uma refer√™ncia hist√≥rica para cada usu√°rio.

Entre as informa√ß√µes consolidadas est√£o:
- Volume total de transa√ß√µes
- Dias ativos do cart√£o
- M√©dia de transa√ß√µes por dia
- Diversidade de linhas, dispositivos e motoristas
- Estat√≠sticas de valor transacionado

Esse hist√≥rico fornece contexto para interpretar cada nova transa√ß√£o.

#### üìä Compara√ß√µes relativas ao comportamento individual

Al√©m de valores absolutos, foram criadas vari√°veis que **comparam cada transa√ß√£o com o pr√≥prio hist√≥rico do cart√£o**, permitindo capturar desvios sutis.

Exemplos de abordagens adotadas:
- Raz√£o entre valor da transa√ß√£o e m√©dia do cart√£o
- Z-score individual do valor transacionado
- Identifica√ß√£o de outliers comportamentais
- Uso acima da m√©dia di√°ria do cart√£o

Esse tipo de feature tende a ser especialmente informativo em cen√°rios reais de fraude, onde desvios graduais podem ser mais relevantes do que picos isolados.

### Resultado da Etapa

Ao final do processo, o dataset encontra-se organizado, documentado e pronto para suportar a compara√ß√£o entre diferentes modelos de machine learning, permitindo an√°lises consistentes de desempenho, interpretabilidade e impacto operacional.

### Exemplos de Features Criadas

A tabela abaixo apresenta algumas das principais features derivadas durante o processo:

| Feature | Descri√ß√£o |
|------|-----------|
| tempo_desde_ultima_transacao_min | Intervalo de tempo, em minutos, desde a √∫ltima transa√ß√£o do cart√£o |
| qtd_linhas_distintas_dia | Quantidade de linhas de √¥nibus distintas utilizadas pelo cart√£o no dia |
| cartao_media_transacoes_por_dia | M√©dia hist√≥rica de transa√ß√µes di√°rias do cart√£o |
| valor_zscore_cartao | Z-score do valor da transa√ß√£o em rela√ß√£o ao hist√≥rico do cart√£o |
| uso_acima_media_dia_cartao | Flag indicando uso di√°rio acima da m√©dia hist√≥rica do cart√£o |

### Avalia√ß√£o de Prontid√£o para Modelagem

Ao final da Etapa, o dataset encontra-se:

- Sem vazamentos de informa√ß√£o em rela√ß√£o √† vari√°vel alvo  
- Com tipagem adequada e categ√≥ricas preparadas para encoding  
- Com auditoria expl√≠cita de valores ausentes, restritos a casos semanticamente esperados  
- Totalmente versionado, documentado e exportado para reutiliza√ß√£o  

Essa estrutura√ß√£o permitiu que a etapa seguinte do projeto fosse dedicada exclusivamente √† constru√ß√£o, compara√ß√£o e avalia√ß√£o de modelos de machine learning, sem necessidade de retrabalho nas fases anteriores.


## ü§ñ Modelagem e Avalia√ß√£o dos Modelos

Com o dataset tratado e enriquecido por meio da engenharia de features, iniciou-se a etapa de modelagem supervisionada com o objetivo de avaliar diferentes algoritmos de Machine Learning aplicados √† detec√ß√£o de fraudes em transa√ß√µes de bilhetagem eletr√¥nica.

Essa etapa foi conduzida seguindo boas pr√°ticas metodol√≥gicas, incluindo valida√ß√£o cruzada estratificada, uso de m√©tricas adequadas a dados desbalanceados e avalia√ß√£o final em conjunto de teste independente. Al√©m do desempenho preditivo, foram considerados crit√©rios de interpretabilidade, estabilidade e impacto operacional, conforme as premissas do problema de neg√≥cio.

### Sele√ß√£o e Justificativa dos Modelos Avaliados

| Modelo | Pr√≥s | Contras | Adequa√ß√£o |
|------|------|--------|----------|
| Regress√£o Log√≠stica | Alta interpretabilidade<br>Coeficientes explic√°veis<br>Baseline robusto | Rela√ß√µes lineares<br>Depende de boas features | Muito alta<br>Baseline interpret√°vel |
| √Årvore de Decis√£o | Regras claras<br>Alta explicabilidade<br>Captura n√£o linearidades | Sens√≠vel a ru√≠do<br>Overfitting sem controle | Alta<br>Boa para explica√ß√£o |
| Random Forest | Boa performance<br>Reduz overfitting<br>Intera√ß√µes complexas | Menor transpar√™ncia<br>Custo computacional maior | Alta<br>Equil√≠brio geral |
| Gradient Boosting | Forte poder preditivo<br>Bom em fraude | Complexidade elevada<br>Dif√≠cil explica√ß√£o | M√©dia |
| XGBoost / LightGBM | Performance de ponta<br>Robusto | Caixa-preta relativa<br>Dif√≠cil uso operacional | M√©dia / Baixa |
| SVM | Bom em certos cen√°rios | Pouco interpret√°vel<br>Escala limitada | Baixa |
| kNN | Simples conceitualmente | N√£o escala bem<br>Dif√≠cil interpreta√ß√£o | Baixa |
| Naive Bayes | R√°pido<br>Simples | Suposi√ß√£o forte<br>Baixa performance | Baixa |

A partir da an√°lise comparativa, foram selecionados tr√™s modelos para avalia√ß√£o pr√°tica no projeto: **Regress√£o Log√≠stica**, **√Årvore de Decis√£o** e **Random Forest**.

A Regress√£o Log√≠stica foi adotada como baseline interpret√°vel, permitindo leitura direta dos coeficientes e maior transpar√™ncia na tomada de decis√£o. A √Årvore de Decis√£o foi inclu√≠da por sua capacidade de capturar n√£o linearidades de forma explic√°vel, enquanto o Random Forest foi utilizado como um ensemble capaz de reduzir vari√¢ncia e explorar intera√ß√µes mais complexas entre as features.

Modelos de maior complexidade, como Gradient Boosting e XGBoost, foram deliberadamente mantidos fora do escopo principal devido √† menor interpretabilidade e √† dificuldade de uso operacional, considerando as restri√ß√µes do problema e os requisitos do case.


### Compara√ß√£o Visual dos Modelos

A figura abaixo apresenta as matrizes de confus√£o dos tr√™s modelos avaliados no conjunto de teste (holdout), considerando threshold padr√£o de 0.5. A visualiza√ß√£o permite comparar diretamente o volume de falsos alertas, fraudes detectadas e fraudes perdidas em cada abordagem.

![Matrizes de Confus√£o dos Modelos](outputs/matrizes_confusao_modelos.png)

Os resultados obtidos indicaram desempenho limitado para todos os modelos avaliados, com m√©tricas pr√≥ximas ao comportamento aleat√≥rio. A an√°lise de diagn√≥stico explorat√≥rio da separabilidade j√° havia evidenciado forte sobreposi√ß√£o entre transa√ß√µes fraudulentas e leg√≠timas no espa√ßo de features, o que se confirmou durante a modelagem.

A Regress√£o Log√≠stica apresentou o melhor desempenho relativo em termos de PR-AUC, estabilidade e interpretabilidade, sendo definida como o modelo vencedor do projeto. Ainda assim, os resultados refor√ßam que o principal limitador do desempenho n√£o est√° na escolha do algoritmo, mas na natureza dos dados dispon√≠veis.

Nesse contexto, os modelos supervisionados atuam de forma mais adequada como ferramentas de **prioriza√ß√£o de risco**, e n√£o como solu√ß√µes definitivas de detec√ß√£o autom√°tica de fraude.


## üìä Resultados Visuais Relevantes

Durante o projeto, algumas visualiza√ß√µes desempenharam papel central na compreens√£o do problema e na interpreta√ß√£o dos resultados obtidos. Em especial:

- A proje√ß√£o por PCA permitiu avaliar visualmente a separabilidade entre transa√ß√µes fraudulentas e leg√≠timas.
- As matrizes de confus√£o possibilitaram a compara√ß√£o direta do comportamento dos modelos no conjunto de teste.
- A an√°lise do trade-off operacional evidenciou o impacto pr√°tico das decis√µes do modelo em termos de alertas e fraudes capturadas.

Essas visualiza√ß√µes complementam a an√°lise quantitativa e est√£o documentadas no notebook de modelagem, servindo como apoio √† interpreta√ß√£o dos resultados.


## üß† Conclus√µes

A avalia√ß√£o dos modelos confirmou que a limita√ß√£o central do problema n√£o est√° associada √† escolha do algoritmo, mas sim √†s caracter√≠sticas do espa√ßo de dados dispon√≠vel. Mesmo ap√≥s a constru√ß√£o de features temporais, comportamentais e agregadas, observou-se baixa separabilidade entre as classes.

Nesse contexto, os modelos supervisionados avaliados apresentam maior adequa√ß√£o como mecanismos de **prioriza√ß√£o de risco**, auxiliando a tomada de decis√£o, do que como solu√ß√µes autom√°ticas de detec√ß√£o definitiva de fraude.


## üöÄ Recomenda√ß√µes e Pr√≥ximos Passos

Considerando um cen√°rio real de aplica√ß√£o, alguns caminhos podem ser explorados para evolu√ß√£o da solu√ß√£o:

- Enriquecimento do dataset com informa√ß√µes adicionais de contexto e localiza√ß√£o.
- Modelagem expl√≠cita de sequ√™ncias temporais por cart√£o, capturando padr√µes de longo prazo.
- Reformula√ß√£o do problema como ranqueamento de risco em vez de classifica√ß√£o bin√°ria r√≠gida.
- Ajuste din√¢mico de thresholds conforme perfil do cart√£o ou contexto operacional.
- Integra√ß√£o do modelo a fluxos de revis√£o humana.
- Explora√ß√£o de abordagens n√£o supervisionadas ou semi-supervisionadas para detec√ß√£o de anomalias.


## üìå Considera√ß√µes Finais

O projeto resultou em um pipeline completo, interpret√°vel e metodologicamente consistente para an√°lise de fraude em bilhetagem eletr√¥nica. Mais do que buscar maximizar m√©tricas, o trabalho concentrou-se em compreender o problema, explicitar limita√ß√µes e propor caminhos realistas de evolu√ß√£o.

A principal contribui√ß√£o est√° na clareza do diagn√≥stico, na avalia√ß√£o cr√≠tica dos trade-offs envolvidos e na constru√ß√£o de uma base s√≥lida para decis√µes futuras em um ambiente operacional real.


## ‚úçÔ∏è Autoria

Este projeto foi desenvolvido por **Let√≠cia Pacheco**, como estudo aplicado em Ci√™ncia de Dados e Aprendizado de M√°quina, com foco em detec√ß√£o de fraude em sistemas de bilhetagem eletr√¥nica.

O trabalho contempla todas as etapas do ciclo de um projeto de Machine Learning, desde a an√°lise explorat√≥ria e engenharia de features at√© a modelagem, avalia√ß√£o cr√≠tica dos resultados e proposi√ß√£o de caminhos de evolu√ß√£o, seguindo boas pr√°ticas metodol√≥gicas e priorizando interpretabilidade e impacto operacional.
